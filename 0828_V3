<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection and Snapshot</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
        }
        #video, #canvas {
            max-width: 100%;
            height: auto;
        }
        button {
            margin: 5px;
        }
        canvas {
            position: absolute;
        }
    </style>
</head>
<body>
    <video id="video" width="300" height="300" autoplay muted></video>
    <canvas id="canvas" width="300" height="300"></canvas><br>
    <button id="camera">啟動攝像頭</button>
    <button id="snap">拍照</button> 
    <button onclick="switchCamera()">切換鏡頭</button>

    <!-- 引入 face-api.js -->
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@0.22.2/dist/face-api.min.js"></script>
    <!-- 引入 OpenCV.js -->
    <script async src="https://docs.opencv.org/3.4/opencv.js" onload="onOpenCvReady();"></script>
    
    <script>
        function onOpenCvReady() {
            console.log('OpenCV.js is ready');
        }

        function getUserMedia(constraints, success, error) {
            if (navigator.mediaDevices.getUserMedia) {
                navigator.mediaDevices.getUserMedia(constraints).then(success).catch(error);
            } else if (navigator.webkitGetUserMedia) {
                navigator.webkitGetUserMedia(constraints, success, error);
            }
        }

        function success(stream) {
            const video = document.getElementById('video');
            video.srcObject = stream;
            video.play();
            startFaceDetection();
        }

        function error(err) {
            console.error("相機訪問失敗: ", err);
        }

        document.getElementById('camera').addEventListener('click', function () {
            const size = 300;
            if (navigator.mediaDevices.getUserMedia || navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia) {
                getUserMedia({ video: { width: size, height: size } }, success, error);
            } else {
                alert("不支持攝像頭");
            }
        });

        document.getElementById('snap').addEventListener('click', function () {
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const context = canvas.getContext('2d');
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            detectFace(canvas);
        });

        function startFaceDetection() {
            const video = document.getElementById('video');

            Promise.all([
                faceapi.nets.tinyFaceDetector.loadFromUri('./models'),
                faceapi.nets.faceLandmark68Net.loadFromUri('./models'),
                faceapi.nets.faceRecognitionNet.loadFromUri('./models'),
                faceapi.nets.faceExpressionNet.loadFromUri('./models')
            ]).then(() => {
                video.addEventListener('play', () => {
                    const canvas = faceapi.createCanvasFromMedia(video);
                    document.body.append(canvas);
                    const displaySize = { width: video.width, height: video.height };
                    faceapi.matchDimensions(canvas, displaySize);

                    setInterval(async () => {
                        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();
                        const resizedDetections = faceapi.resizeResults(detections, displaySize);
                        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                        faceapi.draw.drawDetections(canvas, resizedDetections);
                        faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
                    }, 100);
                });
            }).catch(err => console.error('模型加載錯誤:', err));
        }

        function detectFace(canvas) {
            let src = cv.imread(canvas);
            let gray = new cv.Mat();
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

            let faces = new cv.RectVector();
            let faceCascade = new cv.CascadeClassifier();
            faceCascade.load('haarcascade_frontalface_default.xml');

            let msize = new cv.Size(0, 0);
            faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, msize, msize);

            for (let i = 0; i < faces.size(); ++i) {
                let face = faces.get(i);
                let point1 = new cv.Point(face.x, face.y);
                let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                cv.rectangle(src, point1, point2, [255, 0, 0, 255]);
            }

            cv.imshow(canvas, src);
            src.delete();
            gray.delete();
            faceCascade.delete();
            faces.delete();
        }
    </script>
</body>
</html>
